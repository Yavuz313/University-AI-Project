import json
import os
from langchain.schema import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# ğŸ“Œ GeliÅŸmiÅŸ embedding modeli (Daha iyi kelime eÅŸleÅŸmesi saÄŸlar)
embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/multi-qa-mpnet-base-dot-v1",
    encode_kwargs={"normalize_embeddings": True}
)

# ğŸ“Œ Q&A Verisini YÃ¼kle ve BÃ¶l
def load_qa_and_create_vectorstore():
    with open("MyQ&A_cleaned.json", "r", encoding="utf-8") as f:
        qa_data = json.load(f)

    # ğŸ“Œ Veriyi uygun formatta dÃ¶nÃ¼ÅŸtÃ¼r
    documents = [
        Document(page_content=f"Question: {item['QUESTION']}\nAnswer: {item['ANSWER']}")
        for item in qa_data
    ]

    # ğŸ“Œ Metinleri belirli parÃ§alara ayÄ±rarak vektÃ¶r veritabanÄ±na uygun hale getir
    text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=200)
    split_docs = text_splitter.split_documents(documents)  # âœ… split_docs artÄ±k tanÄ±mlandÄ±!

    # ğŸ“Œ ChromaDB'yi oluÅŸtur ve verileri sakla
    vectordb = Chroma.from_documents(split_docs, embedding_model, persist_directory="./vistula_chroma")

    return vectordb.as_retriever()
